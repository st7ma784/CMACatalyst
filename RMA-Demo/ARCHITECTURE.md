# RMA Distributed System Architecture

## Overview

The RMA (Return Merchandise Authorization) Distributed System is a democratized compute pool that enables distributed AI workloads across volunteer worker nodes with minimal central infrastructure cost.

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENTS / USERS                         â”‚
â”‚                    (Web Browsers, API Calls)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ADMIN DASHBOARD                            â”‚
â”‚           https://rma-dashboard.fly.dev                         â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Real-time worker monitoring                                 â”‚
â”‚  â€¢ System health metrics                                       â”‚
â”‚  â€¢ Worker statistics & distribution                            â”‚
â”‚  â€¢ Auto-refresh every 5 seconds                               â”‚
â”‚                                                                 â”‚
â”‚  Stack: React + Vite + Recharts                               â”‚
â”‚  Hosted: Fly.io (Free Tier - 256MB RAM)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COORDINATOR SERVICE                            â”‚
â”‚          https://rma-coordinator.fly.dev                        â”‚
â”‚                                                                 â”‚
â”‚  Core Responsibilities:                                         â”‚
â”‚  â”œâ”€ Worker Registration & Discovery                            â”‚
â”‚  â”œâ”€ Tier Assignment (GPU/Service/Data)                        â”‚
â”‚  â”œâ”€ Health Monitoring (30s heartbeats)                        â”‚
â”‚  â”œâ”€ Request Routing & Load Balancing                          â”‚
â”‚  â”œâ”€ Container Assignment Logic                                â”‚
â”‚  â””â”€ Admin API (stats, workers, health)                        â”‚
â”‚                                                                 â”‚
â”‚  Stack: Python FastAPI + Uvicorn                              â”‚
â”‚  Hosted: Fly.io (Free Tier - 256MB RAM)                      â”‚
â”‚  Auto-scaling: Scale to zero when idle                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚              â”‚                   â”‚
    â–¼                 â–¼              â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIER 1  â”‚    â”‚ TIER 1  â”‚    â”‚ TIER 2  â”‚      â”‚ TIER 3  â”‚
â”‚  GPU    â”‚    â”‚  GPU    â”‚    â”‚ SERVICE â”‚      â”‚  DATA   â”‚
â”‚ Worker  â”‚    â”‚ Worker  â”‚    â”‚ Worker  â”‚      â”‚ Worker  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Worker Tier System

### Tier 1: GPU Workers (High Compute)
**Hardware Requirements:**
- NVIDIA GPU (8GB+ VRAM recommended)
- 8+ CPU cores
- 16GB+ RAM

**Assigned Containers:**
- `vllm-worker` - LLM inference (Llama, Mistral, etc.)
- `ollama-vision-worker` - Vision models & OCR
- `gpu-compute-worker` - General GPU workloads

**Use Cases:**
- Large language model inference
- Image generation & processing
- OCR with AI enhancement
- Computer vision tasks

### Tier 2: Service Workers (CPU Intensive)
**Hardware Requirements:**
- 4+ CPU cores
- 8GB+ RAM
- No GPU required

**Assigned Containers:**
- `rag-worker` - Retrieval Augmented Generation
- `ner-worker` - Named Entity Recognition
- `notes-worker` - Document processing
- `chromadb-worker` - Vector database

**Use Cases:**
- Document embedding & search
- Text analysis & NER
- API services
- RAG pipeline processing

### Tier 3: Data Workers (Storage/Cache)
**Hardware Requirements:**
- 2+ CPU cores
- 4GB+ RAM
- Storage space

**Assigned Containers:**
- `postgres-worker` - PostgreSQL database
- `redis-worker` - Cache & session storage
- `neo4j-worker` - Graph database

**Use Cases:**
- Data persistence
- Caching layer
- Session management
- Graph relationships

---

## Deployment Models

### Model 1: Local Development

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Developer Machine                                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Coordinator Service                        â”‚        â”‚
â”‚  â”‚  http://localhost:8080                      â”‚        â”‚
â”‚  â”‚  (Python FastAPI)                           â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                 â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                                              â”‚        â”‚
â”‚  â–¼                                              â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Worker Agent     â”‚              â”‚ Admin Dashboard â”‚ â”‚
â”‚  â”‚  (Python Script)  â”‚              â”‚ http://3001     â”‚ â”‚
â”‚  â”‚                   â”‚              â”‚ (React Dev)     â”‚ â”‚
â”‚  â”‚  Detects:         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚  â€¢ Hardware caps  â”‚                                  â”‚
â”‚  â”‚  â€¢ Registers      â”‚                                  â”‚
â”‚  â”‚  â€¢ Runs containersâ”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                          â”‚
â”‚  Docker Containers:                                     â”‚
â”‚  â”œâ”€ vllm-worker (if GPU)                               â”‚
â”‚  â”œâ”€ rag-worker                                         â”‚
â”‚  â””â”€ chromadb-worker                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Setup Commands:**
```bash
# Terminal 1: Start Coordinator
cd coordinator-service
python -m uvicorn app.main:app --host 0.0.0.0 --port 8080

# Terminal 2: Start Worker Agent
cd worker-agent
python worker_agent.py --coordinator http://localhost:8080

# Terminal 3: Start Dashboard
cd admin-dashboard
npm run dev
```

---

### Model 2: Fly.io Production Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FLY.IO CLOUD                              â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  rma-coordinator.fly.dev (Coordinator)                     â”‚ â”‚
â”‚  â”‚  â€¢ Auto-scales to zero when idle                           â”‚ â”‚
â”‚  â”‚  â€¢ Wakes on API request                                    â”‚ â”‚
â”‚  â”‚  â€¢ 256MB RAM, shared CPU                                   â”‚ â”‚
â”‚  â”‚  â€¢ Free tier eligible                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  rma-dashboard.fly.dev (Admin Dashboard)                   â”‚ â”‚
â”‚  â”‚  â€¢ Static site (React build + Nginx)                       â”‚ â”‚
â”‚  â”‚  â€¢ 256MB RAM                                                â”‚ â”‚
â”‚  â”‚  â€¢ Free tier eligible                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTPS
                        â”‚ (Public Internet)
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                               â”‚                  â”‚
        â–¼                               â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Home PC      â”‚            â”‚  Office Server â”‚   â”‚  Cloud VM      â”‚
â”‚  (GPU Worker) â”‚            â”‚  (CPU Worker)  â”‚   â”‚  (CPU Worker)  â”‚
â”‚               â”‚            â”‚                â”‚   â”‚                â”‚
â”‚  Docker:      â”‚            â”‚  Docker:       â”‚   â”‚  Docker:       â”‚
â”‚  â€¢ GPU worker â”‚            â”‚  â€¢ CPU worker  â”‚   â”‚  â€¢ CPU worker  â”‚
â”‚  container    â”‚            â”‚    container   â”‚   â”‚    container   â”‚
â”‚               â”‚            â”‚                â”‚   â”‚                â”‚
â”‚  Connects to: â”‚            â”‚  Connects to:  â”‚   â”‚  Connects to:  â”‚
â”‚  coordinator  â”‚            â”‚  coordinator   â”‚   â”‚  coordinator   â”‚
â”‚  via HTTPS    â”‚            â”‚  via HTTPS     â”‚   â”‚  via HTTPS     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Worker Deployment Commands:**
```bash
# On any machine with Docker
docker run -d \
  --name rma-cpu-worker \
  -e COORDINATOR_URL=https://rma-coordinator.fly.dev \
  --restart unless-stopped \
  rma-cpu-worker:latest

# On GPU machine
docker run -d \
  --name rma-gpu-worker \
  --gpus all \
  -e COORDINATOR_URL=https://rma-coordinator.fly.dev \
  --restart unless-stopped \
  rma-gpu-worker:latest
```

---

### Model 3: Hybrid Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CENTRAL INFRASTRUCTURE                       â”‚
â”‚                     (Fly.io Free Tier - $0/mo)                  â”‚
â”‚                                                                  â”‚
â”‚  Coordinator + Dashboard                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Communityâ”‚     â”‚Universityâ”‚     â”‚ Small   â”‚     â”‚Individualâ”‚
   â”‚ Member  â”‚     â”‚ Lab      â”‚     â”‚Business â”‚     â”‚Developer â”‚
   â”‚         â”‚     â”‚          â”‚     â”‚         â”‚     â”‚          â”‚
   â”‚GPU: RTX â”‚     â”‚GPU: A100 â”‚     â”‚CPU: 32  â”‚     â”‚CPU: Rpi â”‚
   â”‚3060     â”‚     â”‚(4x)      â”‚     â”‚cores    â”‚     â”‚4GB      â”‚
   â”‚Tier 1   â”‚     â”‚Tier 1    â”‚     â”‚Tier 2   â”‚     â”‚Tier 3   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Each contributes compute capacity to the distributed pool
   All workers auto-register and receive workloads based on tier
```

---

## Communication Flow

### 1. Worker Registration Flow
```
Worker                 Coordinator
  â”‚                         â”‚
  â”œâ”€ Detect Hardware â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  (GPU, CPU, RAM)        â”‚
  â”‚                         â”‚
  â”œâ”€ POST /api/worker/      â”‚
  â”‚  register               â”‚
  â”‚  {capabilities: {...}}  â”‚
  â”‚                         â”‚
  â”‚                         â”œâ”€ Assign Tier
  â”‚                         â”œâ”€ Select Containers
  â”‚                         â”œâ”€ Create Worker Record
  â”‚                         â”‚
  â”‚ â—„â”€ Return Assignment â”€â”€â”€â”¤
  â”‚  {worker_id,            â”‚
  â”‚   tier,                 â”‚
  â”‚   containers: [...]}    â”‚
  â”‚                         â”‚
  â”œâ”€ Pull Container Images  â”‚
  â”œâ”€ Start Containers       â”‚
  â”‚                         â”‚
  â””â”€ Begin Heartbeats â”€â”€â”€â”€â”€â”€â”¤
     (every 30s)            â”‚
```

### 2. Heartbeat Flow
```
Worker                 Coordinator
  â”‚                         â”‚
  â”œâ”€ POST /api/worker/      â”‚
  â”‚  heartbeat              â”‚
  â”‚  {worker_id,            â”‚
  â”‚   status: "healthy",    â”‚
  â”‚   current_load: 0.45}   â”‚
  â”‚                         â”‚
  â”‚                         â”œâ”€ Update Last Heartbeat
  â”‚                         â”œâ”€ Update Status
  â”‚                         â”œâ”€ Check Health
  â”‚                         â”‚
  â”‚ â—„â”€ 200 OK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                         â”‚
  â”‚                         â”‚
  â”‚ (after 90s no heartbeat)â”‚
  â”‚                         â”œâ”€ Mark as Offline
  â”‚                         â”œâ”€ Remove from Pool
  â”‚                         â”‚
```

### 3. Dashboard Monitoring Flow
```
Dashboard              Coordinator
  â”‚                         â”‚
  â”œâ”€ GET /api/admin/stats â”€â”€â”¤
  â”‚                         â”œâ”€ Calculate Stats
  â”‚                         â”‚
  â”‚ â—„â”€ Return Stats â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  {total_workers,        â”‚
  â”‚   healthy_workers,      â”‚
  â”‚   by_tier: {...}}       â”‚
  â”‚                         â”‚
  â”œâ”€ GET /api/admin/workersâ”€â”¤
  â”‚                         â”œâ”€ List All Workers
  â”‚                         â”‚
  â”‚ â—„â”€ Return Workers â”€â”€â”€â”€â”€â”€â”¤
  â”‚  [{worker_id,           â”‚
  â”‚    tier, status, ...}]  â”‚
  â”‚                         â”‚
  â””â”€ Refresh (every 5s) â”€â”€â”€â”€â”¤
```

---

## Data Models

### Worker
```python
{
  "worker_id": "worker-abc12345",
  "tier": 2,
  "status": "healthy",  # healthy | degraded | offline
  "ip_address": "192.168.1.100",
  "registered_at": "2025-12-01T10:00:00Z",
  "last_heartbeat": "2025-12-01T10:05:30Z",
  "current_load": 0.45,  # 0.0 - 1.0
  "tasks_completed": 127,
  "capabilities": {
    "cpu_cores": 16,
    "ram": "64.0GB",
    "storage": "1TB",
    "gpu_memory": "24GB",
    "gpu_type": "NVIDIA RTX 4090"
  },
  "assigned_containers": [
    {
      "name": "rma-vllm-worker",
      "image": "ghcr.io/rma/vllm-worker:latest",
      "port": 8000,
      "env": {"MODEL": "llama2:7b"}
    }
  ]
}
```

### Container Assignment
```python
{
  "name": "rma-vllm-worker",
  "image": "ghcr.io/rma/vllm-worker:latest",
  "port": 8000,
  "requires_gpu": True,
  "env": {
    "MODEL": "llama2:7b",
    "COORDINATOR_URL": "https://rma-coordinator.fly.dev"
  }
}
```

---

## API Endpoints

### Worker API (`/api/worker`)
- `POST /register` - Register new worker
- `POST /heartbeat` - Send heartbeat update
- `DELETE /unregister/{id}` - Graceful shutdown
- `GET /tasks` - Pull tasks (future)
- `POST /task-complete` - Report completion (future)

### Admin API (`/api/admin`)
- `GET /workers` - List all workers
- `GET /stats` - System statistics
- `GET /health` - Detailed health check

### Inference API (`/api/inference`) - Future
- `POST /llm` - LLM inference request
- `POST /rag/query` - RAG query
- `POST /ocr` - OCR processing
- `POST /vision` - Vision model inference

---

## Security Considerations

### Current (MVP)
- âœ… HTTPS for all communication
- âœ… Fly.io managed SSL certificates
- âœ… No sensitive data in transit
- âœ… Workers connect outbound only

### Future Enhancements
- ğŸ”„ JWT authentication for workers
- ğŸ”„ API keys for admin endpoints
- ğŸ”„ Rate limiting per worker
- ğŸ”„ Encrypted worker credentials
- ğŸ”„ Network isolation (VPN/Tailscale)

---

## Scaling Strategy

### Horizontal Scaling
```
1 Worker  â”€â”€â–º 10 Workers  â”€â”€â–º 100 Workers  â”€â”€â–º 1000 Workers
   â”‚              â”‚                â”‚                  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              Same coordinator cost: $0/month
              (Fly.io free tier handles 1000+ workers)
```

### Performance Characteristics
- **Worker Registration**: < 1 second
- **Heartbeat Processing**: < 50ms
- **Admin Dashboard Queries**: < 200ms
- **Coordinator Memory**: ~1-2MB per 100 workers

### Bottlenecks & Solutions
1. **Coordinator CPU**: Minimal (heartbeats are async)
2. **Coordinator Memory**: Workers stored in-memory (add Redis for 1000+)
3. **Network**: Fly.io free tier handles 100GB/month (sufficient for 1000 workers)

---

## Cost Comparison

### Before (Centralized)
```
GPU Server (AWS g5.xlarge):     $1.006/hour = $~730/month
Load Balancer:                  $20/month
Database:                       $15/month
Monitoring:                     $10/month
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                          $775/month
```

### After (Distributed)
```
Coordinator (Fly.io free):      $0/month
Dashboard (Fly.io free):        $0/month
Workers (Community donated):    $0/month
Domain (optional):              $1/month
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                          $1/month

SAVINGS:                        $774/month (99.9%)
```

---

## Monitoring & Observability

### Real-time Metrics
- Total workers by tier
- Healthy vs degraded workers
- Average load per tier
- Tasks completed
- Worker uptime

### Health Checks
- Coordinator: `/health`
- Workers: Heartbeat status
- Containers: Health check endpoints
- Dashboard: Uptime monitoring

### Alerting (Future)
- Worker offline > 5 minutes
- No GPU workers available
- Coordinator unhealthy
- High system load (>80%)

---

## Future Enhancements

### Phase 1 (Current)
- âœ… Worker registration & discovery
- âœ… Tier-based assignment
- âœ… Health monitoring
- âœ… Admin dashboard

### Phase 2 (Next)
- ğŸ”„ Task queue system
- ğŸ”„ Request routing to workers
- ğŸ”„ Load balancing algorithm
- ğŸ”„ Worker authentication

### Phase 3 (Future)
- ğŸ“‹ Credit system for contributors
- ğŸ“‹ Priority queue for donors
- ğŸ“‹ Reputation scoring
- ğŸ“‹ Automatic failover
- ğŸ“‹ Multi-region support

---

## Technical Stack

### Coordinator
- **Language**: Python 3.11+
- **Framework**: FastAPI 0.115+
- **Server**: Uvicorn (ASGI)
- **Deployment**: Fly.io Docker

### Dashboard
- **Language**: JavaScript (ES6+)
- **Framework**: React 18
- **Build Tool**: Vite 5
- **Charts**: Recharts
- **Hosting**: Fly.io (Nginx)

### Workers
- **Language**: Python 3.11+
- **Container**: Docker
- **GPU**: NVIDIA Container Toolkit
- **Orchestration**: Docker Compose

---

## Getting Started

See [DISTRIBUTED_QUICK_START.md](./DISTRIBUTED_QUICK_START.md) for step-by-step deployment guide.

For detailed deployment instructions, see [DEPLOYMENT_COMPLETE.md](./DEPLOYMENT_COMPLETE.md).
