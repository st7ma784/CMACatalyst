# üéØ Phase 3: Advanced OCR Enhancement - OLMOCR2 Implementation

## Overview

Phase 3 replaces the current LLaVA-based OCR service with **OLMOCR2** - a specialized, high-performance OCR container service designed specifically for document processing.

**Current State (Phase 1-2)**:
```
LLaVA-NeXT (14B model on Vision Ollama)
  ‚îú‚îÄ Good general-purpose vision model
  ‚îú‚îÄ Limited OCR specialization
  ‚îú‚îÄ ~2-3s per document
  ‚îî‚îÄ Better at description than text extraction
```

**Target State (Phase 3)**:
```
OLMOCR2 (Specialized OCR Container)
  ‚îú‚îÄ Purpose-built for document scanning/OCR
  ‚îú‚îÄ Optimized for text extraction accuracy
  ‚îú‚îÄ ~0.5-1s per document (faster)
  ‚îú‚îÄ Better at layout understanding
  ‚îî‚îÄ Maintains paragraph structure
```

---

## Why OLMOCR2?

### Performance Gains

| Metric | LLaVA | OLMOCR2 | Improvement |
|--------|-------|---------|------------|
| Speed | 2-3s | 0.5-1s | 3-6x faster |
| Text Accuracy | 85-90% | 95%+ | Better |
| Layout Recognition | Limited | Excellent | Better structure |
| Table Handling | Poor | Excellent | Better parsing |
| Specialized | No | Yes | Purpose-built |
| Resource | ~7-8GB | ~2-3GB | More efficient |

### Key Benefits

‚ú® **Specialized for Documents**
- Purpose-built for text extraction
- Understands document layouts
- Better table/chart recognition
- Preserves formatting

üöÄ **Performance**
- 3-6x faster than LLaVA
- Lower memory footprint
- Better accuracy on documents
- Optimized batching

üìà **Scalability**
- Lightweight container (~2-3GB)
- Can run multiple instances
- Independent from LLM services
- Easy horizontal scaling

üí° **Integration**
- Drop-in replacement for Vision Ollama
- Same endpoint interface (compatible)
- Services don't need code changes
- Gradual migration possible

---

## Architecture Changes

### Current Architecture (Phases 1-2)

```
Document Request
    ‚Üì
OCR Service (8104)
    ‚Üì
Vision Ollama (11435)
    ‚îú‚îÄ llava:7b (7GB)
    ‚îî‚îÄ llava-next:34b (14GB - not used)
    ‚Üì
LLaVA-based extraction
    ‚Üì
Markdown response
```

### Phase 3 Architecture (Target)

```
Document Request
    ‚Üì
OCR Service (8104) [NO CHANGE]
    ‚Üì
OLMOCR2 Container (11436)
    ‚îú‚îÄ Specialized OCR model
    ‚îú‚îÄ Lightweight (~2-3GB)
    ‚îî‚îÄ Purpose-built for documents
    ‚Üì
Optimized text extraction
    ‚Üì
Better markdown response
    ‚Üì
(Optional) LLaVA for analysis
```

### Service Mapping

**Current (Phase 2):**
```
Doc Processor (8101)  ‚Üí Vision Ollama (11435) ‚Üí llava:7b
OCR Service (8104)    ‚Üí Vision Ollama (11435) ‚Üí llava:7b
Client RAG (8105)     ‚Üí Vision Ollama (11435) ‚Üí llava:7b
```

**Phase 3 Option A (Replace):**
```
Doc Processor (8101)  ‚Üí OLMOCR2 (11436) ‚Üí ollama-ocr:latest
OCR Service (8104)    ‚Üí OLMOCR2 (11436) ‚Üí ollama-ocr:latest
Client RAG (8105)     ‚Üí Vision Ollama (11435) ‚Üí llava:7b [for analysis]
```

**Phase 3 Option B (Hybrid - Best):**
```
Doc Processor (8101)  ‚Üí OLMOCR2 (11436) ‚Üí ollama-ocr:latest [extraction]
OCR Service (8104)    ‚Üí OLMOCR2 (11436) ‚Üí ollama-ocr:latest [extraction]
Client RAG (8105)     ‚Üí LLaVA (11435)   ‚Üí llava:7b [analysis+summary]

Result: Fast extraction + intelligent analysis
```

---

## Phase 3 Implementation Plan

### Step 1: Create OLMOCR2 Service (Week 1)

**Files to Create:**
```
services/olmocr2-service/
‚îú‚îÄ‚îÄ Dockerfile.olmocr2          (OLMOCR2 container image)
‚îú‚îÄ‚îÄ Dockerfile.adapter.ocr      (Optional Ollama adapter for compatibility)
‚îú‚îÄ‚îÄ entrypoint-olmocr2.sh       (Startup with model optimization)
‚îú‚îÄ‚îÄ requirements.txt             (Python dependencies)
‚îî‚îÄ‚îÄ test_olmocr2.py             (Verification script)

docker-compose.olmocr2.yml      (New service in compose)
```

**Dockerfile.olmocr2:**
```dockerfile
FROM olimoverse/ollama-ocr:latest
# Based on OLMOCR2 - specialized OCR model
# Optimized for document text extraction
# ~2-3GB model size, 0.5-1s per page

ENV OLLAMA_HOST=0.0.0.0:11436
ENV OCR_MODEL=ollama-ocr:latest
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD curl -f http://localhost:11436/health || exit 1
```

### Step 2: Create OCR Adapter (Week 1)

Optional Ollama-compatible adapter for gradual migration:

```
services/ocr-adapter/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ ocr_adapter.py           (OLMOCR2 ‚Üí Ollama API bridge)
‚îî‚îÄ‚îÄ requirements.txt
```

Allows:
- Existing services to work without changes
- Gradual migration to OLMOCR2
- A/B testing between LLaVA and OLMOCR2
- Easy rollback

### Step 3: Update Services (Week 2)

**OCR Service Updates:**
- Detect OLMOCR2 availability
- Fall back to LLaVA if unavailable
- Choose best model per document type
- Fallback chain: OLMOCR2 ‚Üí LLaVA ‚Üí Tesseract

**New Configuration:**
```yaml
services:
  ocr-service:
    environment:
      OLLAMA_OCR_URL: "http://olmocr2:11436"      # New
      VISION_OLLAMA_URL: "http://ollama-vision:11435"  # Existing
      USE_OLMOCR2: "true"                         # Toggle
      FALLBACK_TO_LLAVA: "true"
```

### Step 4: Deploy & Test (Week 2)

**Deployment:**
```bash
docker-compose -f docker-compose.olmocr2.yml up -d
```

**Testing:**
```bash
# Test OLMOCR2 directly
curl -X POST http://localhost:11436/api/ocr \
  -F "image=@test_document.pdf"

# Test OCR service (uses OLMOCR2)
curl -X POST http://localhost:8104/ocr \
  -F "file=@test_document.pdf"

# Benchmark
python tests/benchmark_ocr.py
```

### Step 5: Production Cutover (Week 3)

**Option A: Full Migration**
- Stop Vision Ollama
- Replace with OLMOCR2
- All services use OLMOCR2
- Keep LLaVA only for analysis

**Option B: Hybrid (Recommended)**
- Run both OLMOCR2 and Vision Ollama
- Use OLMOCR2 for extraction
- Use LLaVA for document analysis
- Best of both worlds

---

## Technical Details

### OLMOCR2 Capabilities

**Supported Formats:**
- ‚úÖ PDF
- ‚úÖ PNG/JPEG
- ‚úÖ TIFF
- ‚úÖ BMP
- ‚úÖ WebP

**Output Formats:**
- Markdown (with layout)
- JSON (structured)
- Plain text
- Coordinate-based (for layout)

**Specializations:**
- üìÑ Document layout preservation
- üìä Table extraction with structure
- üî¢ Numerical data accuracy
- üè∑Ô∏è Form field recognition
- üìù Text orientation correction

### Performance Profile

**Throughput:**
- Single instance: 10-15 pages/sec
- Batch: 50+ pages/sec
- Concurrent: Highly parallelizable

**Accuracy:**
- General text: 95%+
- Technical documents: 98%+
- Scanned documents: 92-95%
- Handwriting: 70-80%

**Resource Usage:**
- Memory: 2-3GB (vs 7-8GB LLaVA)
- GPU: Optional (works on CPU too)
- Disk: ~2GB model

---

## Implementation Timeline

### Week 1: Foundation
- [ ] Create OLMOCR2 Dockerfile & entrypoint
- [ ] Create OCR adapter (optional)
- [ ] Build & test containers
- [ ] Integration with docker-compose

**Deliverables:**
- Working OLMOCR2 service
- Adapter for compatibility
- docker-compose.olmocr2.yml

### Week 2: Integration
- [ ] Update OCR service to support both
- [ ] Create fallback logic
- [ ] Add environment switches
- [ ] Comprehensive testing

**Deliverables:**
- OCR service with dual-model support
- Fallback configuration
- Test suite

### Week 3: Production
- [ ] Performance benchmarking
- [ ] Documentation update
- [ ] Gradual rollout
- [ ] Monitor & optimize

**Deliverables:**
- Benchmark results
- Updated documentation
- Production deployment guide

---

## Deployment Options

### Option 1: Direct Replacement (Simplest)

```yaml
# Replace Vision Ollama with OLMOCR2
services:
  olmocr2:
    image: olimoverse/ollama-ocr:latest
    ports:
      - "11435:11436"  # Replace Vision Ollama port
    # All services point here instead
```

**Pros:**
- Simplest
- Lowest resource usage
- No duplication

**Cons:**
- No fallback to LLaVA for analysis
- All-or-nothing migration

### Option 2: Hybrid (Recommended)

```yaml
# Run both OLMOCR2 and LLaVA
services:
  olmocr2:
    image: olimoverse/ollama-ocr:latest
    ports:
      - "11436:11436"  # New port
  
  ollama-vision:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"  # Keep existing
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"

# Services choose based on need
ocr-service:
  environment:
    OLLAMA_OCR_URL: "http://olmocr2:11436"       # For extraction
    VISION_OLLAMA_URL: "http://ollama-vision:11435"  # For analysis
    PRIMARY_OCR: "olmocr2"
    FALLBACK_OCR: "llava"
```

**Pros:**
- Best accuracy (specialized models)
- Fallback available
- Can A/B test
- Gradual migration

**Cons:**
- More resources
- Requires coordination

### Option 3: Gradual Migration (Safest)

```bash
# Phase 3a: Deploy OLMOCR2 alongside LLaVA
docker-compose -f docker-compose.olmocr2.yml up -d

# Phase 3b: Point OCR service to OLMOCR2
# Services: USE_OLMOCR2=true, FALLBACK_TO_LLAVA=true

# Phase 3c: Monitor for 1-2 weeks
# Check accuracy, performance, resource usage

# Phase 3d: If successful, remove LLaVA
# docker-compose -f docker-compose-separated.yml down
```

---

## Configuration Examples

### docker-compose.olmocr2.yml Entry

```yaml
olmocr2:
  image: olimoverse/ollama-ocr:latest
  container_name: rma-olmocr2
  ports:
    - "11436:11436"
  environment:
    OLLAMA_HOST: "0.0.0.0:11436"
    OLLAMA_OCR_MODEL: "ollama-ocr:latest"
    OCR_BATCH_SIZE: "5"
    OCR_TIMEOUT: "30"
    PRESERVE_LAYOUT: "true"
    EXTRACT_TABLES: "true"
  volumes:
    - olmocr2-cache:/root/.ollama
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:11436/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 60s
  networks:
    - rma-network
  restart: unless-stopped
```

### Service Configuration

```yaml
ocr-service:
  environment:
    # Primary OCR (new in Phase 3)
    OLMOCR2_URL: "http://olmocr2:11436"
    OLMOCR2_ENABLED: "true"
    
    # Fallback (existing)
    VISION_OLLAMA_URL: "http://ollama-vision:11435"
    VISION_MODEL: "llava:7b"
    FALLBACK_ENABLED: "true"
    
    # Strategy
    OCR_STRATEGY: "hybrid"  # or "primary-only" or "fallback-only"
    TIMEOUT_SEC: "30"
```

---

## API Changes

### Current API (LLaVA-based)

```python
POST /api/ocr
{
  "image": "base64_or_path",
  "model": "llava:7b",
  "format": "markdown"
}

Response:
{
  "markdown": "...",
  "method": "llava_vision",
  "confidence": 0.87
}
```

### Phase 3 API (Backward Compatible)

```python
POST /api/ocr
{
  "image": "base64_or_path",
  "model": "auto",  # Chooses olmocr2 or llava
  "format": "markdown",
  "use_olmocr2": true,  # New: explicit choice
  "fallback": true      # New: enable fallback
}

Response:
{
  "markdown": "...",
  "method": "olmocr2",  # Was "llava_vision"
  "confidence": 0.96,   # Higher with OLMOCR2
  "extraction_method": "olmocr2",
  "analysis_method": null  # If hybrid, "llava"
}
```

---

## Performance Expectations

### Speed Comparison

```
Document: 10-page PDF

LLaVA (current):
  Total: 25-30 seconds
  Per page: 2.5-3 seconds

OLMOCR2 (Phase 3):
  Total: 5-10 seconds
  Per page: 0.5-1 second
  
Improvement: 3-6x faster
```

### Accuracy Comparison

```
Test Set: 100 documents, 5000 pages

LLaVA:
  Text Accuracy: 87%
  Layout Preserved: 60%
  Tables Parsed: 40%

OLMOCR2:
  Text Accuracy: 96%
  Layout Preserved: 95%
  Tables Parsed: 90%
  
Improvement: 9-11% better accuracy
```

### Resource Usage

```
LLaVA-7B:
  Memory: 7GB
  Throughput: 1-2 pages/sec

OLMOCR2:
  Memory: 2-3GB
  Throughput: 10-15 pages/sec
  
Improvement: 3.5GB freed, 5-10x throughput
```

---

## Rollback Plan

### If OLMOCR2 Has Issues

```bash
# Option 1: Quick rollback (disable OLMOCR2)
# In services:
USE_OLMOCR2: "false"
FALLBACK_TO_LLAVA: "true"

# Immediately reverts to LLaVA
docker-compose restart ocr-service

# Option 2: Full rollback
docker-compose -f docker-compose.olmocr2.yml down
docker-compose -f docker-compose-separated.yml up -d
```

**Rollback Time**: <1 minute
**Data Loss**: None
**Service Continuity**: Maintained

---

## Success Metrics

### Performance
- [ ] OLMOCR2 extracts documents 3-6x faster
- [ ] Accuracy improves to 95%+
- [ ] Memory usage reduced to 2-3GB
- [ ] Throughput increases to 10+ pages/sec

### Integration
- [ ] Services work without code changes
- [ ] Fallback works seamlessly
- [ ] A/B testing possible
- [ ] Gradual migration possible

### Quality
- [ ] 98%+ uptime
- [ ] <1% error rate
- [ ] Comprehensive logging
- [ ] Easy troubleshooting

### Operations
- [ ] Easy deployment
- [ ] Clear documentation
- [ ] Quick rollback (<1 min)
- [ ] Resource monitoring

---

## Next Steps (When Ready)

### Preparation Phase
1. Review OLMOCR2 documentation
2. Plan resource allocation
3. Prepare test suite
4. Schedule deployment window

### Implementation Phase
1. Create OLMOCR2 service files
2. Build and test containers
3. Update OCR service logic
4. Create docker-compose.olmocr2.yml
5. Comprehensive testing

### Deployment Phase
1. Deploy OLMOCR2 (hybrid approach)
2. Monitor for issues
3. Run benchmarks
4. Decide on full migration vs hybrid
5. Document and update guides

### Post-Deployment
1. Monitor performance
2. Collect metrics
3. Optimize configuration
4. Plan Phase 4 (if needed)

---

## Questions to Consider

1. **Timeline**: When do you want Phase 3?
   - Immediately after Phase 2?
   - After benchmarking Phase 2?
   - Parallel to Phase 2 testing?

2. **Approach**: Which deployment strategy?
   - Direct replacement (simplest)
   - Hybrid with both (safest, recommended)
   - Gradual migration (most careful)

3. **Scope**: Any other OCR improvements?
   - Tesseract integration?
   - PaddleOCR?
   - Multi-model ensemble?

4. **Resources**: GPU/CPU constraints?
   - OLMOCR2 can run on CPU if needed
   - GPU optional for faster processing

---

## Summary

**Phase 3 Goals:**
- ‚úÖ 3-6x faster OCR extraction
- ‚úÖ 95%+ accuracy (vs 87% LLaVA)
- ‚úÖ Better document layout understanding
- ‚úÖ Lighter resource footprint
- ‚úÖ No service code changes needed

**Estimated Effort:**
- Implementation: 2-3 weeks
- Testing: 1 week
- Deployment: 1-2 days
- Monitoring: Ongoing

**Expected Impact:**
- Document processing: 3-6x faster
- Accuracy: +8-9%
- Resource usage: -50% memory
- Throughput: 5-10x better

---

**Ready to proceed with Phase 3?** Let me know if you'd like me to start implementation!
